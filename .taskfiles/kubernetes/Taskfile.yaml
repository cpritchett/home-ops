---
version: "3"

tasks:
  browse-pvc:
    desc: Mount a PVC to an temp container [NS={{.NS}}] [CLAIM=required]
    interactive: true
    cmd: kubectl browse-pvc --namespace {{.NS}} --image docker.io/library/alpine:latest {{.CLAIM}}
    vars:
      NS: '{{.NS | default "default"}}'
    requires:
      vars: [CLAIM]
    preconditions:
      - kubectl --namespace {{.NS}} get persistentvolumeclaims {{.CLAIM}}
      - kubectl browse-pvc --version
      - which kubectl

  node-shell:
    desc: Open a shell to a node [NS={{.NS}}] [NODE=required]
    interactive: true
    cmd: kubectl node-shell -n {{.NS}} -x {{.NODE}}
    vars:
      NS: '{{.NS | default "kube-system"}}'
    requires:
      vars: [NODE]
    preconditions:
      - kubectl get nodes {{.NODE}}
      - kubectl node-shell --version
      - which kubectl

  sync-secrets:
    desc: Force sync all ExternalSecrets (and fix 1Password Connect if needed)
    cmds:
      - echo "üîç Checking 1Password Connect status..."
      - |
        if ! kubectl get clustersecretstore onepassword -o jsonpath='{.status.conditions[0].status}' | grep -q "True"; then
          echo "‚ùå 1Password Connect not working, fixing..."
          cat {{.BOOTSTRAP_DIR}}/secrets.yaml.tpl | op inject | kubectl apply -f -
          kubectl delete pod -l app.kubernetes.io/name=onepassword -n external-secrets
          echo "‚è≥ Waiting for 1Password Connect to restart..."
          kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=onepassword -n external-secrets --timeout=60s
        else
          echo "‚úÖ 1Password Connect is healthy"
        fi
      - echo "üîÑ Force syncing all ExternalSecrets..."
      - for: { var: SECRETS, split: "\n" }
        cmd: kubectl --namespace {{splitList "," .ITEM | first}} annotate externalsecret {{splitList "," .ITEM | last}} force-sync="{{now | unixEpoch}}" --overwrite
      - echo "‚úÖ Secret sync complete"
    vars:
      SECRETS:
        sh: kubectl get externalsecret --all-namespaces --no-headers --output=jsonpath='{range .items[*]}{.metadata.namespace},{.metadata.name}{"\n"}{end}'
    preconditions:
      - op user get --me
      - test -f {{.BOOTSTRAP_DIR}}/secrets.yaml.tpl
      - which kubectl op

  cleanse-pods:
    desc: Cleanse pods with a Failed/Pending/Succeeded phase
    cmds:
      - for:
          matrix:
            PHASE: [Failed, Pending, Succeeded]
        cmd: kubectl delete pods --all-namespaces --field-selector status.phase={{.ITEM.PHASE}} --ignore-not-found=true
    preconditions:
      - which kubectl

  reconcile:
    desc: Force Flux reconciliation to pull latest Git changes
    cmds:
      - echo "üîÑ Reconciling Git source..."
      - flux reconcile source git flux-system -n flux-system
      - echo "üîÑ Reconciling cluster applications..."
      - flux reconcile kustomization cluster-apps -n flux-system
      - echo "‚úÖ Flux reconciliation complete"
    preconditions:
      - which flux

  # https://docs.github.com/en/enterprise-cloud@latest/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/deploying-runner-scale-sets-with-actions-runner-controller#upgrading-arc
  upgrade-arc:
    desc: Upgrade the ARC
    cmds:
      - helm -n actions-runner-system uninstall home-ops-runner
      - helm -n actions-runner-system uninstall actions-runner-controller
      - sleep 5
      - flux -n actions-runner-system reconcile hr actions-runner-controller
      - flux -n actions-runner-system reconcile hr home-ops-runner
    preconditions:
      - which flux helm

  suspend-namespace:
    desc: Suspend all Flux Kustomizations in a namespace [NAMESPACE=required]
    summary: |
      Suspend all Flux Kustomizations in a namespace to stop reconciliation.

      Usage: task kubernetes:suspend-namespace NAMESPACE=media

      Note: This only prevents future reconciliation - existing pods remain until manually deleted.
    requires:
      vars: [NAMESPACE]
    cmds:
      - |
        echo "Suspending all Kustomizations in namespace: {{.NAMESPACE}}"
        kubectl get kustomizations -n {{.NAMESPACE}} --no-headers -o custom-columns=":metadata.name" | \
        xargs -I {} flux suspend kustomization {} -n {{.NAMESPACE}}
      - echo "‚úÖ All Kustomizations in {{.NAMESPACE}} namespace suspended"

  resume-namespace:
    desc: Resume all Flux Kustomizations in a namespace [NAMESPACE=required]
    summary: |
      Resume all Flux Kustomizations in a namespace to restore reconciliation.

      Usage: task kubernetes:resume-namespace NAMESPACE=media
    requires:
      vars: [NAMESPACE]
    cmds:
      - |
        echo "Resuming all Kustomizations in namespace: {{.NAMESPACE}}"
        kubectl get kustomizations -n {{.NAMESPACE}} --no-headers -o custom-columns=":metadata.name" | \
        xargs -I {} flux resume kustomization {} -n {{.NAMESPACE}}
      - echo "‚úÖ All Kustomizations in {{.NAMESPACE}} namespace resumed"

  delete-namespace-pods:
    desc: Delete all pods in a namespace [NAMESPACE=required]
    summary: |
      Delete all pods in a namespace to free resources immediately.

      Usage: task kubernetes:delete-namespace-pods NAMESPACE=media

      Warning: This forcefully deletes all pods in the namespace.
    requires:
      vars: [NAMESPACE]
    cmds:
      - |
        echo "‚ö†Ô∏è  WARNING: This will delete ALL pods in namespace: {{.NAMESPACE}}"
        read -p "Are you sure? (y/N): " confirm
        if [[ $confirm == [yY] ]]; then
          kubectl delete pods -n {{.NAMESPACE}} --all --grace-period=0 --force
          echo "‚úÖ All pods in {{.NAMESPACE}} namespace deleted"
        else
          echo "‚ùå Operation cancelled"
        fi

  delete-deployment:
    desc: Delete a specific deployment and its pods [DEPLOYMENT=required NAMESPACE=required]
    summary: |
      Delete a specific deployment and all its pods.

      Usage: task kubernetes:delete-deployment DEPLOYMENT=autobrr NAMESPACE=media
    requires:
      vars: [DEPLOYMENT, NAMESPACE]
    cmds:
      - |
        echo "Deleting deployment: {{.DEPLOYMENT}} in namespace: {{.NAMESPACE}}"
        kubectl delete deployment {{.DEPLOYMENT}} -n {{.NAMESPACE}} --grace-period=0 --force
        echo "‚úÖ Deployment {{.DEPLOYMENT}} deleted from {{.NAMESPACE}} namespace"

  nuke-namespace:
    desc: Nuclear option - suspend kustomizations AND delete all pods [NAMESPACE=required]
    summary: |
      Nuclear option: Suspend all Flux Kustomizations AND delete all pods in namespace.

      Usage: task kubernetes:nuke-namespace NAMESPACE=media

      Warning: This completely stops and cleans a namespace.
    requires:
      vars: [NAMESPACE]
    cmds:
      - |
        echo "üö® NUCLEAR OPTION: This will suspend all Kustomizations AND delete all pods in: {{.NAMESPACE}}"
        read -p "Are you absolutely sure? (type 'NUKE' to confirm): " confirm
        if [[ $confirm == "NUKE" ]]; then
          if ! task kubernetes:suspend-namespace NAMESPACE={{.NAMESPACE}}; then
            echo "‚ùå Failed to suspend namespace"
            exit 1
          fi
          sleep 2
          if ! kubectl delete pods -n {{.NAMESPACE}} --all --grace-period=0 --force; then
            echo "‚ùå Failed to delete pods"
            exit 1
          fi
          echo "üí• Namespace {{.NAMESPACE}} has been nuked"
        else
          echo "‚ùå Operation cancelled"
        fi

  scale-deployment:
    desc: Scale a deployment to specific replica count [DEPLOYMENT=required NAMESPACE=required REPLICAS=required]
    summary: |
      Scale a deployment to a specific number of replicas.

      Usage: task kubernetes:scale-deployment DEPLOYMENT=autobrr NAMESPACE=media REPLICAS=0
    requires:
      vars: [DEPLOYMENT, NAMESPACE, REPLICAS]
    cmds:
      - |
        echo "Scaling deployment {{.DEPLOYMENT}} in {{.NAMESPACE}} to {{.REPLICAS}} replicas"
        kubectl scale deployment {{.DEPLOYMENT}} -n {{.NAMESPACE}} --replicas={{.REPLICAS}}
        echo "‚úÖ Deployment {{.DEPLOYMENT}} scaled to {{.REPLICAS}} replicas"

  restart-deployment:
    desc: Restart a deployment by rolling it out [DEPLOYMENT=required NAMESPACE=required]
    summary: |
      Restart a deployment by triggering a rollout restart.

      Usage: task kubernetes:restart-deployment DEPLOYMENT=autobrr NAMESPACE=media
    requires:
      vars: [DEPLOYMENT, NAMESPACE]
    cmds:
      - |
        echo "Restarting deployment: {{.DEPLOYMENT}} in namespace: {{.NAMESPACE}}"
        kubectl rollout restart deployment {{.DEPLOYMENT}} -n {{.NAMESPACE}}
        echo "‚úÖ Deployment {{.DEPLOYMENT}} restart initiated"
        kubectl rollout status deployment {{.DEPLOYMENT}} -n {{.NAMESPACE}} --timeout=300s

  check-resource-pressure:
    desc: Check cluster resource pressure and identify constraining pods
    summary: |
      Check cluster resource pressure and identify pods consuming the most resources.
    cmds:
      - |
        PROBLEMATIC_STATUSES="(Pending|CrashLoopBackOff|Error|ImagePullBackOff)"

        echo "üìä Cluster Resource Pressure Analysis"
        echo "======================================"
        echo ""
        echo "üñ•Ô∏è  Node Resource Usage:"
        if ! kubectl top nodes 2>/dev/null; then
          echo "‚ùå Failed to get node metrics"
          exit 1
        fi
        echo ""
        echo "üî• Top 10 CPU Consuming Pods:"
        cpu_output=$(kubectl top pods -A --sort-by=cpu 2>/dev/null)
        if [[ $? -eq 0 && -n "$cpu_output" ]]; then
          echo "$cpu_output" | head -11 || true  # Handle SIGPIPE gracefully
        else
          echo "‚ùå Failed to get pod CPU metrics"
          exit 1
        fi
        echo ""
        echo "üíæ Top 10 Memory Consuming Pods:"
        memory_output=$(kubectl top pods -A --sort-by=memory 2>/dev/null)
        if [[ $? -eq 0 && -n "$memory_output" ]]; then
          echo "$memory_output" | head -11 || true  # Handle SIGPIPE gracefully
        else
          echo "‚ùå Failed to get pod memory metrics"
          exit 1
        fi
        echo ""
        echo "‚ö†Ô∏è  Problematic Pods:"
        problematic_pods=$(kubectl get pods -A 2>/dev/null | grep -E "$PROBLEMATIC_STATUSES" || true)
        if [[ -n "$problematic_pods" ]]; then
          echo "$problematic_pods"
        else
          echo "‚úÖ No problematic pods found"
        fi
        echo ""
        echo "üìã Summary:"
        total_pods=$(kubectl get pods -A --no-headers 2>/dev/null | wc -l || echo "unknown")
        running_pods=$(kubectl get pods -A --no-headers 2>/dev/null | grep -c "Running" || echo "unknown")
        echo "Total pods: $total_pods | Running: $running_pods"

  force-pod-delete:
    desc: Force delete a stuck pod [POD=required NAMESPACE=required]
    summary: |
      Force delete a stuck pod with grace period 0.

      Usage: task kubernetes:force-pod-delete POD=autobrr-xyz NAMESPACE=media
    requires:
      vars: [POD, NAMESPACE]
    cmds:
      - |
        echo "Force deleting pod: {{.POD}} in namespace: {{.NAMESPACE}}"
        kubectl delete pod {{.POD}} -n {{.NAMESPACE}} --grace-period=0 --force
        echo "‚úÖ Pod {{.POD}} force deleted"

  nuke-app:
    desc: Nuclear option - completely purge an app and let Flux rebuild [APP=required NAMESPACE=required]
    summary: |
      Nuclear option: Completely destroy an app including Helm releases, secrets, 
      configmaps, volumes, and all Kubernetes resources, then let Flux rebuild.

      Usage: task k8s:nuke-app APP=cloudflared NAMESPACE=networking

      This will:
      1. Suspend the Flux HelmRelease to stop reconciliation
      2. Delete the Helm release completely
      3. Delete all app-related secrets (including Helm release secrets)
      4. Delete all app-related configmaps
      5. Delete all app-related PVCs/volumes
      6. Force delete all pods/deployments/replicasets
      7. Resume Flux reconciliation to rebuild everything clean

      Warning: This completely destroys the app and rebuilds from Git.
    requires:
      vars: [APP, NAMESPACE]
    cmds:
      - |
        set -euo pipefail

        # Function for safer command execution with error handling
        safe_delete() {
          local resource_type="$1"
          local namespace="$2"
          local app="$3"
          local label_selector="app.kubernetes.io/name=$app"
          
          echo "Deleting $resource_type with label $label_selector..."
          kubectl delete "$resource_type" -n "$namespace" -l "$label_selector" --ignore-not-found=true || echo "‚ö†Ô∏è  Failed to delete labeled $resource_type"
          
          echo "Deleting additional $resource_type matching '$app'..."
          # Temporarily disable strict error checking for this section
          set +e
          local resources=""
          resources=$(kubectl get "$resource_type" -n "$namespace" --no-headers 2>/dev/null | grep "$app" | awk '{print $1}' 2>/dev/null)
          local grep_exit_code=$?
          set -e
          
          set -e
          
          if [[ -n "$resources" ]]; then
            echo "$resources" | xargs -r kubectl delete "$resource_type" -n "$namespace" || echo "‚ö†Ô∏è  Failed to delete some $resource_type"
          else
            echo "No additional $resource_type found matching '$app'"
          fi
        }

        echo "üö® NUCLEAR APP DESTRUCTION: {{.APP}} in namespace {{.NAMESPACE}}"
        echo "This will completely destroy and rebuild the application!"
        read -p "Type 'NUKE {{.APP}}' to confirm: " confirm
        if [[ $confirm != "NUKE {{.APP}}" ]]; then
          echo "‚ùå Operation cancelled"
          exit 1
        fi

        echo "üîÑ Step 1: Suspending Flux HelmRelease..."
        if kubectl get helmrelease {{.APP}} -n {{.NAMESPACE}} >/dev/null 2>&1; then
          flux suspend helmrelease {{.APP}} -n {{.NAMESPACE}}
          echo "‚úÖ HelmRelease {{.APP}} suspended"
        else
          echo "‚ö†Ô∏è  No HelmRelease found for {{.APP}}"
        fi

        echo "üóëÔ∏è  Step 2: Deleting Helm release..."
        if helm list -n {{.NAMESPACE}} | grep -q {{.APP}}; then
          helm uninstall {{.APP}} -n {{.NAMESPACE}}
          echo "‚úÖ Helm release {{.APP}} deleted"
        else
          echo "‚ö†Ô∏è  No Helm release found for {{.APP}}"
        fi

        echo "üîë Step 3: Deleting app-related secrets..."
        safe_delete "secrets" "{{.NAMESPACE}}" "{{.APP}}"
        echo "‚úÖ App secrets deleted"

        echo "üìã Step 4: Deleting app-related configmaps..."
        safe_delete "configmaps" "{{.NAMESPACE}}" "{{.APP}}"
        echo "‚úÖ App configmaps deleted"

        echo "‚ò†Ô∏è  Step 5: Force deleting all app resources..."
        echo "Deleting pods..."
        kubectl delete pods -n {{.NAMESPACE}} -l app.kubernetes.io/name={{.APP}} --grace-period=0 --force --ignore-not-found=true || echo "‚ö†Ô∏è  Failed to delete some pods"
        echo "Deleting replicasets..."
        kubectl delete replicasets -n {{.NAMESPACE}} -l app.kubernetes.io/name={{.APP}} --grace-period=0 --force --ignore-not-found=true || echo "‚ö†Ô∏è  Failed to delete some replicasets"
        echo "Deleting deployments..."
        kubectl delete deployments -n {{.NAMESPACE}} -l app.kubernetes.io/name={{.APP}} --grace-period=0 --force --ignore-not-found=true || echo "‚ö†Ô∏è  Failed to delete some deployments"
        echo "Deleting HPAs..."
        safe_delete "hpa" "{{.NAMESPACE}}" "{{.APP}}"
        echo "‚úÖ All app resources deleted"

        echo "‚è≥ Waiting for resource cleanup..."
        sleep 10

        echo "üíæ Step 6: Deleting app-related PVCs..."
        safe_delete "pvc" "{{.NAMESPACE}}" "{{.APP}}"
        echo "‚úÖ App PVCs deleted"

        echo "‚è≥ Step 7: Waiting for cleanup..."
        sleep 5

        echo "üîÑ Step 8: Resuming Flux HelmRelease for clean rebuild..."
        if kubectl get helmrelease {{.APP}} -n {{.NAMESPACE}} >/dev/null 2>&1; then
          echo "Resuming HelmRelease..."
          flux resume helmrelease {{.APP}} -n {{.NAMESPACE}} || echo "‚ö†Ô∏è  Failed to resume HelmRelease"
          echo "Forcing reconciliation..."
          flux reconcile helmrelease {{.APP}} -n {{.NAMESPACE}} || echo "‚ö†Ô∏è  Failed to reconcile HelmRelease"
          echo "‚úÖ Flux reconciliation resumed"
        else
          echo "‚ö†Ô∏è  No HelmRelease to resume - check Git configuration"
        fi

        echo "üí• App {{.APP}} has been completely nuked and rebuild initiated"
        echo "üìã Monitor with: kubectl get pods -n {{.NAMESPACE}} -w"
        echo "üìã Check HelmRelease: flux get helmreleases -n {{.NAMESPACE}} {{.APP}}"
